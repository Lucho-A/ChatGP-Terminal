#### v1.1.3:2023XXXX-Under Dev./Testing

Features:
- option '--import-history' added. This option allows to import a history chat file (formatted as generated by '--csv-format'). The chats to be imported are the latest ones, and the number of them is defined by '--max-context-messages' (default 3). I think that, for the moment, the main objective of this feature could be the chance of continuing a previous session...anyway, just take into account the openai restrictions, and the costs involved.  

Bug-Fixed:
- fixed some json miss-parsing from user's message.

Others:
- in order to avoid/minimize the risk of delimiter/content-mistakes, I changed the delimiter character for '--csv-format' option, from ';' to '	' (\t);
- code optimized, minor changes & code cleaned-up

#### v1.1.2:20230907

Features:
- option '--tts' added. This option allows to speech the response in a selected language (can be cancelled with Crl+C). Dependency: libespeak-ng1. Usage: --tts [es|en|fr...]
- option '--csv-format' added. In order to allow generating a database of useful or particular responses (1), this option allows to save ('save;') records in delimited (';') format, in a file specified with '--save-messages-to'.

Others:
- default velocity response default value change to 10000
- code optimized, minor changes & code cleaned-up

(1) Actually, I'm working on incorporate, in a future release, an 'import' option in order to allow populating the history at the start of the program. 

#### v1.1.1:20230905

Features:
- option '--save-message-to' added. This option allows to specify a file (v.gr. '/home/user/chatgpt-messages.txt') in order to save the latest user & assistant message entering 'save;' into prompt. 

Others:
- code optimization, minor changes & code cleaned-up

#### v1.1.0:20230807

Bug-Fixed:
- fixed 'segmentation fault' when '--max-context-messages 1'

Others:
- removed option '--no-create-context'. You can obtain the same result setting '--max-context-messages 0'. 

#### v1.0.9:20230727

Others:
- changed '--response-velocity' default value to 20000
- changed '--max-context-messages' default value to 3 
- changed '--max-tokens' default value to 512 
- code optimization, minor changes & code cleaned-up

#### v1.0.8:20230725

Features:
- option '--max-context-messages'. Maximum number of chat history (5 as default). The program keep track of the latest N messages sent/responded in order to obtain a better chat experience. Take into account that the tokens in 'context' messages are part of the cost (see show-total-tokens).
- option '--show-prompt-tokens'. No argument required. If the option is specified, shows the tokens include in the prompt (user messages). This value included the previous prompts in  history (users, and assistant ones).
- option '--show-completion-tokens'. No argument required. If the option is specified, shows the tokens include in the response.
- 'flush;' command. Typing 'flush;' into the prompt, flush the history of messages.

Others:
- code optimization & code cleaned-up

#### v1.0.7:20230723

Bug-Fixed:
- parsed message fixed.
- crashes fixed.

Others:
- code optimization & code cleaned-up

#### v1.0.6:20230723

Features:
- Accepts as option '--no-create-context'. If set, a context (historical of user's prompt and responses) won't be generated (FALSE by default).

Others:
- code optimization & code cleaned-up

#### v1.0.5:20230722

Features:
- Accepts as option '--show-finished-status'. If set, shows the response 'Total tokens' at the end of the response

Others:
- increased default timeouting to 60s
- code optimization, minor changes & code cleaned-up

#### v1.0.4:20230720

Bugs-Fixed:
- command argument input validations 
- user prompt string parsed fixed when '\n'

Others:
- improved string memory assignment.
- minor changes & code cleaned-up

#### v1.0.3:20230719

Bugs-Fixed:
- (I think) prompt (user's input) & readline() prompt solved
- Others like '%' on output

Others:
- default receiving message timeouting increased (35s)
- minor changes & code cleaned-up

#### v1.0.2:20230719

Improvements:
- Accepts as option '--show-finished-status'. If set, shows the status at the end of the answers.
	
Bugs-Fixed:
- Some I don't remember hhaha

Others:
- Show 'errno' description if getting info errors occurs.
- minor changes & code cleaned-up

#### v1.0.1:20230719

Improvements:
- allowing cancel by user handling signal ('SIGINT').
	
Bugs-Fixed:
- a lot (string parsings, data validations, error messages, not exit if errors, etc.).

Bugs-Known:
- readline() has some troubles for handling "e[0;XXm". I replaced #defines by "\033[0;XXm" in order to evaluate if behavior changes.
- JSON content message errors because absence of validation and parsing of user's messages ('?','\', etc). 

#### v1.0.0:20230718
- First version.
